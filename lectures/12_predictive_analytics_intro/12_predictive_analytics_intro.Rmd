---
title: "ISA 419: Data Driven Security"
subtitle: "12 - A Very Brief Introduction to Predictive Analytics"
author: Fadel M. Megahed
institute: |
  | Endres Associate Professor
  | Department of Information Systems and Analytics
  | Farmer School of Business
  | Miami University
  | Email: fmegahed@miamioh.edu
  | Office Hours: [Automated Scheduler for Office Hours](https://calendly.com/fmegahed)
  | 
date: "Fall 2022"
output:
  beamer_presentation:
    number_sections: false
    toc: false
    slide_level: 3
    includes: 
      in_header: ../../style_files/structure.txt
latex_engine: xelatex
urlcolor: links
linkcolor: links
classoption: "aspectratio=169"
always_allow_html: yes
bibliography: refs.bib
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      verbose = FALSE,
                      progress = FALSE,
                      fig.align = "center",
                      fig.pos = 'p',
                      fig.width = 5,
                      fig.height= 2.5,
                      allowframebreaks = TRUE,
                      fig.margin=TRUE,
                      kable.force.latex = TRUE,
                      cache = TRUE)
options(kableExtra.latex.load_packages = FALSE)
pacman::p_load(kableExtra, tidyverse, xtable)
```

# Preface 

### What we covered in the past couple of weeks?

- **Introduction to Data Encoding** 

- **The importance of data visualization **  

- **The principles of data Visualization**   

- **An overview of clustering techniques**


### Learning Objectives for Today's Class

- **Define what do we mean by machine learning** 

- **Explain the different types of learning** 

- **Describe the different steps in using machine learning for predictive modeling applications**


# The Basics of Machine Learning

### Definition

**@mitchell2006discipline has elgontely defined the scientific field of machine learning to be centered around answering the following question:**

\vspace{0.5\baselineskip}

\begin{quotation}
\noindent ``How can we build computer systems that automatically improve with experience, and what
are the fundamental laws that govern all learning processes?''
\end{quotation}

**In his view, machine learning is the study of algorithms that:**  

  - **improve its performance** *P*  
  - **at task** *T*   
  - **following experience** *E* 


### A Paradigm Shift in Programming 

\begin{center}
\href{https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781789616729/1/ch01lvl1sec10/defining-machine-learning-and-why-we-need-it}{\includegraphics[width=\linewidth, height=0.7\textheight, keepaspectratio, frame]{../../figures/mltp.png}}

Source: Image is from Yuxi Lui (2019). Python Machine Learning by Example. Packt Publishers (click on image for more details).
\end{center}

### Defining the Learning Task {.allowframebreaks}

\begin{center}
  \textbf{\textcolor{miamired}{Improve	on	task	T,	with	respect	to performance	metric	P,	based	on experience	E
}}
\end{center}

\vspace{0.5\baselineskip}

\begin{columns}
  \begin{column}{0.48\textwidth}
    \begin{itemize}
      \item \textbf{T: Playing checkers}
      \item \textbf{P: Percentage of games won against an arbitrary opponent}
      \item \textbf{E: Playing practice games against itself}
    \end{itemize}
  \end{column}
  \begin{column}{0.48\textwidth}
    \centering \href{https://commons.wikimedia.org/wiki/File:Pool_checkers_(Jamaica).jpg}{\includegraphics[height=0.5\textheight]{../../figures/Pool_checkers_(Jamaica).jpg}}
  \end{column}
\end{columns}

Note: This idea in @samuel1959some led to the popularization of machine learning. 


\begin{center}
  \textbf{\textcolor{miamired}{Improve	on	task	T,	with	respect	to performance	metric	P,	based	on experience	E
}}
\end{center}

\vspace{0.5\baselineskip}

\begin{columns}
  \begin{column}{0.48\textwidth}
    \begin{itemize}
      \item \textbf{T: Autonomous driving using LADAR sensing}
      \item \textbf{P: Average distance traveled before human-judged error}
      \item \textbf{E: A sequence of images and steering commands recorded while
observing a human driver}
    \end{itemize}
  \end{column}
  \begin{column}{0.48\textwidth}
    \centering \href{https://commons.wikimedia.org/wiki/File:Waymo_Chrysler_Pacifica_in_Los_Altos,_2017.jpg}{\includegraphics[height=0.5\textheight]{../../figures/1920px-Waymo_Chrysler_Pacifica_in_Los_Altos,_2017.jpg}}
  \end{column}
\end{columns}

\begin{center}
  \scriptsize Sources: Image by Dllu - Own work, CC BY-SA 4.0, \url{https://commons.wikimedia.org/w/index.php?curid=64517567} and text from \url{https://www.seas.upenn.edu/~cis519/fall2017/lectures/01_introduction.pdf}
\end{center}


\begin{center}
  \textbf{\textcolor{miamired}{Improve	on	task	T,	with	respect	to performance	metric	P,	based	on experience	E
}}
\end{center}

\vspace{0.5\baselineskip}

\begin{columns}
  \begin{column}{0.48\textwidth}
    \begin{itemize}
      \item \textbf{T: Categorizing network traffic as begnin or portmap (or another DDoS attack)}
      \item \textbf{P: Percentage of correctly categorized observations in each group}
      \item \textbf{E: Database of network traffic, with human given labels}
    \end{itemize}
  \end{column}
  \begin{column}{0.48\textwidth}
    \centering \href{https://commons.wikimedia.org/wiki/File:Ddos-attack-ex.png}{\includegraphics[height=0.5\textheight, frame]{../../figures/Ddos-attack-ex.png}}
  \end{column}
\end{columns}


### History of Machine Learning (click for source) [1]

\begin{center}
\href{https://towardsdatascience.com/a-weird-introduction-to-deep-learning-7828803693b0}{\includegraphics[width=\textwidth, trim={0 2 0 3.5in}, clip, frame]{../../figures/1_Z_DnCyKt18RM0aCCrFzaIQ.png}}
\end{center}

### History of Machine Learning (click for source) [2]

\begin{center}
\href{https://twitter.com/evankirstel/status/1036675274287525896/photo/1}{\includegraphics[height=0.82\textheight, trim={0 0 0 2in}, clip, frame]{../../figures/decadesofAI.jpg}}
\end{center}


# From Task (T) to Model Type

### Types of Learning (from Class 03)

\centering 

\href{https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html}{\includegraphics[width=\textwidth, height=0.8\textheight, keepaspectratio, frame]{../../figures/ml_map.png}}
    
\footnotesize \textbf{Source:} SciKit-Learn @scikit2020choosing.


### Supervised Learning: Regression {.allowframebreaks}

- **Given:** $(x_1, y_1), \, (x_2, y_2), \, \dots , (x_n, y_n)$  

- **Learn a function** $f(x)$ **to predict** $y$ **given** $x$    

  - **If** $y$ **is a real-valued variable (i.e. can be assumed to be continuous), then we do have a regression type problem.**  
  
  - **Note in this class, we do not limit ourselves to simple and multiple linear regression. You should be open-minded to benchmarking their performance against other machine learning methodologies.** 
  
    - *Simple linear regression:* single predictor $x \longrightarrow y$
    
    - *Multiple linear regression:* multiple predictors $X \longrightarrow y$; $X$ is a vector


```{r gg}
# Build on the example below to answer the following questions:

# (A) Let us plot the data of x = ufo2010 and y = infections using ggplot()
#   (When we plot the data, let us fit a linear regression line in plot)

# (B) Let us examine how we can use R to create a simple linear regression
# on the same data -> summary(OBJECT)

# (C) Let us examine how we can use R to create a multiple linear regression
# on the same data -> summary(OBJECT)

# (D) "ISA 419 class links ZeroAccess Infections to Alien Visitors"??

# (E) What next?

df = read.csv("../../data/zeroAccessUFO.csv")

ggplot(data=df, aes(x = ufo2010, y = infections)) 

```


### Supervised Learning: Classification {.allowframebreaks}

\begin{center}
  \href{https://christophm.github.io/interpretable-ml-book/logistic.html\#example-1}{\includegraphics[width=\textwidth, height=0.65\textheight, keepaspectratio]{../../figures/logistic-function-1.png}}
  
  Source: Please click on image to access Ch 4.2 in Molnar (2019).
\end{center}

- **Given:** $(x_1, y_1), \, (x_2, y_2), \, \dots , (x_n, y_n)$  

- **Learn a function** $f(x)$ **to predict** $y$ **given** $x$    

  - **If** $y$ **is categorical (special case being binary i.e. 2 categories), then we have a classification problem. As in the regression case, the statistical model logistic regression (and/or one of its varients such as LASSO, Ridge Regression, etc) are often used as benchmark model(s)** 
  
  - **For classification problems, let assume that we have a binary classification problem where the outcome** $y$ **is defined as**
  
\begin{equation}
y=
\begin{cases}
  0, & \text{if no attack is happening/successful} \\
  1, & \text{otherwise}
\end{cases}
\end{equation}

**In such a case, the probability of an attack (i.e.** $y=1$**) can be defined as**

\begin{equation}
  P(y=1)=\frac{1}{1+exp(-(\beta_{0}+\beta_{1}x_{1}+\ldots+\beta_{p}x_{p}))}.
\end{equation}

**To ease the interpretation, we can reformulate the equation above as**

\begin{equation}
log\left(\frac{P(y=1)}{1-P(y=1)}\right)=log\left(\frac{P(y=1)}{P(y=0)}\right)=\beta_{0}+\beta_{1}x_{1}+\ldots+\beta_{p}x_{p}.
\end{equation}

See Sec. 4.2 in @molnar2019interpretable for details on model interpretation .

# Measuring a Model's Performance (P) Depending on its Model Type

### Performance Metrics in Regression Problems

**In ML regression problems, the root mean squared error (RMSE) is typically used. It measures the standard deviation of the residuals (prediction errors).** 

\vspace{-0.75in}

```{r rmseExample, echo=F, fig.height=3.65, fig.width=5.5}
# Based on https://stackoverflow.com/a/13119440/10156153
## Generate Sample Data
ufo2010 = c(2,4,6,8,9,4,5,7,8,9,10)
infections = c(4,7,6,5,8,9,5,6,7,9,10)

## Create a dataframe to resemble existing data
mydata = data.frame(ufo2010,infections)

## fit model
fit <- lm(infections~ufo2010, data = mydata)

## Calculate RMSE and other values
rmse <- round(sqrt(mean(resid(fit)^2)), 2)
coefs <- coef(fit)
b0 <- round(coefs[1], 2)
b1 <- round(coefs[2],2)
r2 <- round(summary(fit)$r.squared, 2)

eqn <- bquote("\n \n" ~~ italic(infections) == .(b0) + .(b1)*italic(ufo2010) * ";" ~~ RMSE == .(rmse))


plot(infections ~ ufo2010, data = mydata)
abline(fit)
text(2, 10, eqn, pos = 4)

```

### Performance Metrics in Classification Problems

**In binary classification problems, most metrics can be captured from the confusion matrix. Below, I include a synthetic example for a confusion matrix for a binary classifier, which we will use to define the following terms:**  

\begin{table}
\begin{tabular}{|cc|c|c|}
\hline 
\multicolumn{2}{|c}{\multirow{2}{*}{}} & \multicolumn{2}{|c|}{\textbf{Actual}} \\
\multicolumn{2}{|c|}{} & \textbf{Event} & \textbf{No Event} \\ \hline
\multirow{2}{*}{\textbf{Pred.}} & \textbf{Event} & A & B \\
 & \textbf{No Event} & C & D \\ \hline
\end{tabular}
\end{table}

<!-- see https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/ -->
- Accuracy  
- Sensitivity  
- Specificity  
- Balanced Accuracy  
- Precision  
- Recall  


# A General Approach to ML

### The 7 Steps of ML

\begin{center}
\includemedia[
  width=0.6\linewidth,height=0.3375\linewidth,
  activate=pageopen,
  flashvars={
  modestbranding=1 % no YT logo in control bar
  &autohide=1 % controlbar autohide
  &showinfo=0 % no title and other info before start
  &rel=0 % no related videos after end
}
]{\includegraphics[width=\textwidth]{../../figures/maxresdefault}}{https://www.youtube.com/watch?v=nKW8Ndu7Mjw}
\end{center}

For an overview of these steps, please refer to the [following medium article](https://medium.com/dataseries/7-steps-to-machine-learning-how-to-prepare-for-an-automated-future-78c7918cb35d).

### Comments: Preparing the Data for Modeling {.allowframebreaks}

\centering 

\href{https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6}{\includegraphics[width=\textwidth, height=0.7\textheight, keepaspectratio, frame]{../../figures/fitting.png}}  

Source: [Adi Bronshtein (2017); Towards Data Science](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6).

\href{https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6}{\includegraphics[width=\textwidth, height=0.7\textheight, keepaspectratio, frame]{../../figures/cross-validation.png}}  

Source: [Adi Bronshtein (2017); Towards Data Science](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6).

\href{https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6}{\includegraphics[width=\textwidth, height=0.7\textheight, keepaspectratio, frame]{../../figures/kfoldcv.png}}  

Source: [Adi Bronshtein (2017); Towards Data Science](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6).  




### Comments: Need for Resampling in Unbalanced Data {.allowframebreaks}

**In many security datasets, actual events (e.g., breaches will be rare). When training your model, you will need to account for the rareness by attempting to balance the training data** \textbf{\textcolor{miamired}{(so that you do not end up with a naive model).}} Typical re-sampling techniques include:  

- Random under-sampling;  
- Random over-sampling;  
- Synethetic majority oversampling technique;    

The images in the following slides are based on an example by [Rafael Alencar](https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets).

\centering 

\href{https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets}{\includegraphics[width=\textwidth, height=0.8\textheight, keepaspectratio, frame]{../../figures/data.png}}

\href{https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets}{\includegraphics[width=\textwidth, height=0.8\textheight, keepaspectratio, frame]{../../figures/confMatrix.JPG}}

\href{https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets}{\includegraphics[width=\textwidth, height=0.8\textheight, keepaspectratio, frame]{../../figures/resampling.png}}

\href{https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets}{\includegraphics[width=\textwidth, height=0.8\textheight, keepaspectratio, frame]{../../figures/smote.png}}


# Recap

### Today's Learning Objectives

- **Define what do we mean by machine learning** 

- **Explain the different types of learning**  

- **Describe the different steps in using machine learning for predictive modeling applications**

### References {.allowframebreaks}
::: {#refs}
:::

---

\maketitle